# -*- coding: utf-8 -*-
"""Ranjithkumar_Data Pre-Processing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dsQky679oBKJ7LwDASxjcbi2YLHK_OBE

**Q1. Problem Statement: Data Pre-Processing (Categorical data)**

You are given a dataset – “hotel_bookings.csv.” The dataset has a high number of null and  elements that need to be cleansed;  Your job is to create a separate DataFrame with only categorical columns and  perform the  following operations:
1.	Find the number of null values in each column of the new DataFrame
2.	Replace the null values with mode 
3.	In the "hotel" column, replace the hotel names with "0" and "1" based on the condition that – if, "hotel" = "city_hotel", then "hotel" = "1";  else, "0"
4.	Using the label encoder, assign a unique country code to each country
5.	Using onehot encoder, encode the “month” column

Loading the data into a DataFrame.
"""

import pandas as pd
import numpy as np
hotel_df = pd.read_csv("/content/hotel_bookings.csv")
# set seed for reproducibility
np.random.seed(0)

""" Initial screening of data."""

hotel_df.info()

# look at a few rows of the nfl_data file. I can see a handful of missing data already!
hotel_df.head(5)

""" Finding null values in data."""

# get the number of missing data points per column
hotel_df.isnull().sum()

"""Dropping null columns from data."""

hotel_df =hotel_df.drop(['company','agent'],  axis = 1)
hotel_df.head()

""" Making a different DataFrame with all the categorical data."""

cat_df_hotel = hotel_df.select_dtypes(include=['object']).copy()
cat_df_hotel.head()

""" Finding null values in categorical DataFrame and replacing them with mode."""

print(cat_df_hotel.isnull().sum())

cat_df_hotel = cat_df_hotel.fillna(cat_df_hotel['country'].value_counts().index[0])
print("After replacing null values with mode:")
print(cat_df_hotel.isnull().sum())

""" Describing categorical DataFrame."""

cat_df_hotel.describe()

"""Encoding data from "hotel" column based on condition that - if "hotel" = "City_hotel", 1; else, 0."""

cat_df_hotel_specific = cat_df_hotel.copy()
cat_df_hotel_specific['hotel'] = np.where(cat_df_hotel_specific['hotel'].str.contains('City Hotel'), 1, 0)

cat_df_hotel_specific.sample(10)

""" Assigning a numeric country code to each country using label encoder."""

cat_df_hotel_sklearn = cat_df_hotel.copy()

from sklearn.preprocessing import LabelEncoder

lb_make = LabelEncoder()
cat_df_hotel_sklearn['country_code'] = lb_make.fit_transform(cat_df_hotel['country'])

cat_df_hotel_sklearn.sample(5)

"""Encoding the "arrival_date_month" column, using onehot encoder."""

cat_df_hotel_onehot = cat_df_hotel.copy()
cat_df_hotel_onehot = pd.get_dummies(cat_df_hotel_onehot, columns=['arrival_date_month'])

print(cat_df_hotel_onehot.head())

"""**Q2. Problem Statement: Data Pre-Processing (Exponential data)**

Create a DataFrame to store exponential data using the NumPy random() function as shown in the dataset section below, and perform the following operations:
1.	Using the minmax_scaling() function, scale the data between 0 to 1, and plot the original data and scaled data using the Seaborn library 
2.	Using preprocessing.normalize() function, normalize the data, and plot the original data and normalized data using the Seaborn library

Importing libraries.
"""

# for min_max scaling
from mlxtend.preprocessing import minmax_scaling

# plotting modules
import seaborn as sns
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

""" Creating exponential data using NumPy."""

# generate 1000 data points randomly drawn from an exponential distribution
original_data = np.random.exponential(size = 1000)
df2= pd.DataFrame(original_data)
df2.head()

""" Scaling data between 0 and 1 using minmax_scaling."""

# mix-max scale the data between 0 and 1
scaled_data = minmax_scaling(df2, columns = [0])

# plot both together to compare
fig, ax=plt.subplots(1,2)
sns.distplot(original_data, ax=ax[0])
ax[0].set_title("Original Data")
sns.distplot(scaled_data, ax=ax[1])
ax[1].set_title("Scaled data")

""" Normalizing the data using the preprocessing.normalize() function."""

# normalize the exponential data with preprocessing
from scipy import stats
from sklearn import preprocessing
normalized_data = preprocessing.normalize(df2)

fig, ax=plt.subplots(1,2)
sns.distplot(df2[0], ax=ax[0])
ax[0].set_title("Original Data")
sns.distplot(normalized_data, ax=ax[1])
ax[1].set_title("Normalized data")